<!DOCTYPE html>

<html class="article-header-style-default">
<head>
	
	<title>ZFS:从10Gbps升级到40Gbps网络 - Xjn&#39;s Blog</title>
	<meta charset="utf-8">
	
		<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
	
	<meta name="description" content="0 介绍自TrueNAS Core更新至FreeBSD 13，它的两大免费产品Scale和Core都已经使用上了OpenZFS。既然如此，就直接转投OpenZFS用上Linux了，但考虑到之前一直使用SolarisZFS，可能会对OpenZFS的tuning不太熟悉，就小心翼翼的先使用了一下TrueNAS Scale试手。体验下来我个人不是很喜欢用K3S Containerd，也没有LXC，或者任">
<meta property="og:type" content="article">
<meta property="og:title" content="ZFS:从10Gbps升级到40Gbps网络">
<meta property="og:url" content="https://blog.xjn819.com/post/Upgrade-from-10Gbps-to-40Gbps-network.html">
<meta property="og:site_name" content="Xjn&#39;s Blog">
<meta property="og:description" content="0 介绍自TrueNAS Core更新至FreeBSD 13，它的两大免费产品Scale和Core都已经使用上了OpenZFS。既然如此，就直接转投OpenZFS用上Linux了，但考虑到之前一直使用SolarisZFS，可能会对OpenZFS的tuning不太熟悉，就小心翼翼的先使用了一下TrueNAS Scale试手。体验下来我个人不是很喜欢用K3S Containerd，也没有LXC，或者任">
<meta property="og:locale">
<meta property="og:image" content="https://s2.loli.net/2023/01/08/EpQUks3IynWcbrd.jpg">
<meta property="og:image" content="https://s2.loli.net/2023/02/28/rI1JFL5VfQlDuqk.png">
<meta property="og:image" content="https://s2.loli.net/2023/02/16/6yZpdQtXg7IhUPn.png">
<meta property="og:image" content="https://s2.loli.net/2023/02/16/vSm7T3QYq4KIdtc.png">
<meta property="article:published_time" content="2023-01-08T12:27:50.000Z">
<meta property="article:modified_time" content="2023-02-28T07:57:10.873Z">
<meta property="article:author" content="Seon">
<meta property="article:tag" content="NAS">
<meta property="article:tag" content="Hardware">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s2.loli.net/2023/01/08/EpQUks3IynWcbrd.jpg">

	<meta name="theme-color" content="#212121">
	<meta name="theme-color-rgb" content="33,33,33">
	<meta name="theme-color-origin" content="#212121">
	<meta name="argon-enable-custom-theme-color" content="false">
	<meta name="theme-card-radius" content="4">
	<meta name="theme-version" content="1.0.1">
	<link rel="icon" href="/assets/img/favicon.ico" type="image/x-icon">
	<link rel="shortcut icon" href="/assets/img/favicon.ico" type="image/x-icon">

	
<link rel="stylesheet" href="/assets/argon_css_merged.css">

	
<link rel="stylesheet" href="/style.css">

	
<link rel="stylesheet" href="//fonts.loli.net/css?family=Open+Sans:300,400,600,700|Noto+Serif+SC:300,600&display=swap.css">

	
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

	
<script src="/assets/argon_js_merged.js"></script>

	
<script src="/assets/js/argon.min.js"></script>

	
<script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

	
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>


	<script>
		var argonConfig = {
			language: "zh_CN",
			
				zoomify: {
					duration: 200,
					easing: "cubic-bezier(0.4,0,0,1)",
					scale: 0.9
				},
			
			pangu: "true",
			
				lazyload: {
					threshold: 800,
					effect: "fadeIn"
				},
			
			disable_pjax: false,
			headroom: true
		}
	</script>
	<script>
		var darkmodeAutoSwitch = "false";
		function setDarkmode(enable){
			if (enable == true){
				$("html").addClass("darkmode");
			}else{
				$("html").removeClass("darkmode");
			}
			$(window).trigger("scroll");
		}
		function toggleDarkmode(){
			if ($("html").hasClass("darkmode")){
				setDarkmode(false);
				sessionStorage.setItem("Argon_Enable_Dark_Mode", "false");
			}else{
				setDarkmode(true);
				sessionStorage.setItem("Argon_Enable_Dark_Mode", "true");
			}
		}
		if (sessionStorage.getItem("Argon_Enable_Dark_Mode") == "true"){
			setDarkmode(true);
		}
		function toggleDarkmodeByPrefersColorScheme(media){
			if (sessionStorage.getItem('Argon_Enable_Dark_Mode') == "false" || sessionStorage.getItem('Argon_Enable_Dark_Mode') == "true"){
				return;
			}
			if (media.matches){
				setDarkmode(true);
			}else{
				setDarkmode(false);
			}
		}
		function toggleDarkmodeByTime(){
			if (sessionStorage.getItem('Argon_Enable_Dark_Mode') == "false" || sessionStorage.getItem('Argon_Enable_Dark_Mode') == "true"){
				return;
			}
			let hour = new Date().getHours();
			if (hour < 7 || hour >= 22){
				setDarkmode(true);
			}else{
				setDarkmode(false);
			}
		}
		if (darkmodeAutoSwitch == 'system'){
			var darkmodeMediaQuery = window.matchMedia("(prefers-color-scheme: dark)");
			darkmodeMediaQuery.addListener(toggleDarkmodeByPrefersColorScheme);
			toggleDarkmodeByPrefersColorScheme(darkmodeMediaQuery);
		}
		if (darkmodeAutoSwitch == 'time'){
			toggleDarkmodeByTime();
		}
		if (darkmodeAutoSwitch == 'alwayson'){
			setDarkmode(true);
		}

		function toggleAmoledDarkMode(){
			$("html").toggleClass("amoled-dark");
			if ($("html").hasClass("amoled-dark")){
				localStorage.setItem("Argon_Enable_Amoled_Dark_Mode", "true");
			}else{
				localStorage.setItem("Argon_Enable_Amoled_Dark_Mode", "false");
			}
		}
		if (localStorage.getItem("Argon_Enable_Amoled_Dark_Mode") == "true"){
			$("html").addClass("amoled-dark");
		}else if (localStorage.getItem("Argon_Enable_Amoled_Dark_Mode") == "false"){
			$("html").removeClass("amoled-dark");
		}
	</script>
	<script>
		if (navigator.userAgent.indexOf("Safari") !== -1 && navigator.userAgent.indexOf("Chrome") === -1){
			$("html").addClass("using-safari");
		}
	</script>

	
		
<script src="/assets/vendor/smoothscroll/smoothscroll1.js"></script>

	
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/feed.xml" title="Xjn's Blog" type="application/atom+xml">
</head>



<style id="themecolor_css">
	
	:root{
		--themecolor: #212121;
		--themecolor-dark0: #1B1B1B;
		--themecolor-dark: #141414;
		--themecolor-dark2: #080808;
		--themecolor-dark3: #000000;
		--themecolor-light: #3B3B3B;
		--themecolor-rgbstr: 33,33,33;
		--themecolor-gradient: linear-gradient(150deg,var(--themecolor-light) 15%, var(--themecolor) 70%, var(--themecolor-dark0) 94%);

	}
</style>
<style id="theme_cardradius_css">
	:root{
		--card-radius: 4px;
	}
</style>

<body>
<div id="toolbar">
	<header class="header-global">
		<nav id="navbar-main" class="navbar navbar-main navbar-expand-lg navbar-transparent navbar-light bg-primary headroom--not-bottom headroom--not-top headroom--pinned">
			<div class="container">
				
				<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar_global" aria-controls="navbar_global" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				<a class="navbar-brand" href="/">Xjn&#39;s Blog</a>
				<div class="navbar-collapse collapse" id="navbar_global">
					<div class="navbar-collapse-header">
						<div class="row">
							<div class="col-6 collapse-brand"></div>
							<div class="col-6 collapse-close">
								<button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar_global" aria-controls="navbar_global" aria-expanded="false" aria-label="Toggle navigation">
									<span></span>
									<span></span>
								</button>
							</div>
						</div>
					</div>
					<ul id="navbar_search_btn_mobile" class="navbar-nav align-items-lg-center ml-lg-auto">
						<li class="nav-item" data-toggle="modal" data-target="#argon_search_modal" style="padding-left: 5px;">
							<a class="nav-link nav-link-icon">
								<i class="fa fa-search"></i>
								<span class="nav-link-inner--text d-lg-none">搜索</span>
							</a>
						</li>
					</ul>
					
							<ul class='navbar-nav navbar-nav-hover align-items-lg-center'>
								
										<li class='nav-item'>
											<a href='/' class='nav-link' >
												<i class='ni ni-book-bookmark d-lg-none'></i>
												<span class='nav-link-inner--text'>首页</span>
											</a>
											
										</li>
									
										<li class='nav-item'>
											<a href='/archives' class='nav-link' >
												<i class='ni ni-book-bookmark d-lg-none'></i>
												<span class='nav-link-inner--text'>归档</span>
											</a>
											
										</li>
									
										<li class='nav-item'>
											<a href='/feed.xml' class='nav-link' >
												<i class='ni ni-book-bookmark d-lg-none'></i>
												<span class='nav-link-inner--text'>订阅</span>
											</a>
											
										</li>
									
							</ul>
						
					<ul class="navbar-nav align-items-lg-center ml-lg-auto">
						<li class="nav-item" data-toggle="modal" data-target="#argon_search_modal" id="navbar_search_btn_pc">
							<a class="nav-link nav-link-icon">
								<i class="fa fa-search"></i>
								<span class="nav-link-inner--text d-lg-none">搜索</span>
							</a>
						</li>
					</ul>
				</div>
				
				<div id="navbar_menu_mask" data-toggle="collapse" data-target="#navbar_global"></div>
			</div>
		</nav>
	</header>
</div>
<div class="modal fade" id="argon_search_modal" tabindex="-1" role="dialog" aria-labelledby="" aria-hidden="true">
	<div class="modal-dialog modal-dialog-centered modal-lg" role="document">
		<div class="modal-content">
			<div class="modal-header">
				<h5 class="modal-title">搜索</h5>
				<button type="button" class="close" data-dismiss="modal" aria-label="Close">
					<span aria-hidden="true">&times;</span>
				</button>
			</div>
			<div class="modal-body">
				<!-- TODO -->
<div class="form-group mb-3">
	<div class="input-group input-group-alternative">
		<div class="input-group-prepend">
			<span class="input-group-text"><i class="fa fa-search"></i></span>
		</div>
		<input id="local-search-input" class="form-control" placeholder="搜索什么..." type="text"  autocomplete="off" data-search.path="search.xml" data-config.root="/">
	</div>
	<div id="local-search-result"></div>
</div>
			</div>
		</div>
	</div>
</div>
<!--Banner-->
<section id="banner" class="banner section section-lg section-shaped">
	<div class="shape  shape-primary">
		<span></span>
		<span></span>
		<span></span>
		<span></span>
		<span></span>
		<span></span>
		<span></span>
		<span></span>
		<span></span>
	</div>

	
	<div id="banner_container" class="banner-container container text-center">
		
			<div class="banner-title text-white"><span class="banner-title-inner">Xjn´s Blog</span>
		
		</div>
	</div>
	
		<style>
			section.banner{
				background-image: url(/assets/img/banner.jpg) !important;
			}
		</style>
	
</section>


	<style>
		#content:before {
			content: '';
			display: block;
			position: fixed;
			left: 0;
			right: 0;
			top: 0;
			bottom: 0;
			z-index: -2;
			background: url(/assets/img/banner.jpg);
			background-position: center;
			background-size: cover;
			background-repeat: no-repeat;
			opacity: 1;
			transition: opacity .5s ease;
		}
		html.darkmode #content:before{
			filter: brightness(0.65);
		}
		
			#content:after {
				content: '';
				display: block;
				position: fixed;
				left: 0;
				right: 0;
				top: 0;
				bottom: 0;
				z-index: -2;
				background: url(/assets/img/banner.jpg);
				background-position: center;
				background-size: cover;
				background-repeat: no-repeat;
				opacity: 0;
				transition: opacity .5s ease;
			}
			html.darkmode #content:after {
				opacity: 1;
			}
			html.darkmode #content:before {
				opacity: 0;
			}
		
		
			#banner, #banner .shape {
				background: transparent !important;
			}
		
	</style>




<div id="float_action_buttons" class="float-action-buttons fabtns-unloaded">
	<button id="fabtn_toggle_sides" class="btn btn-icon btn-neutral fabtn shadow-sm" type="button" aria-hidden="true" tooltip-move-to-left="移至左侧" tooltip-move-to-right="移至右侧">
		<span class="btn-inner--icon fabtn-show-on-right"><i class="fa fa-caret-left"></i></span>
		<span class="btn-inner--icon fabtn-show-on-left"><i class="fa fa-caret-right"></i></span>
	</button>
	<button id="fabtn_back_to_top" class="btn btn-icon btn-neutral fabtn shadow-sm" type="button" aria-label="Back To Top" tooltip="回到顶部">
		<span class="btn-inner--icon"><i class="fa fa-angle-up"></i></span>
	</button>
	<button id="fabtn_go_to_comment" class="btn btn-icon btn-neutral fabtn shadow-sm d-none" type="button" <-% theme.fab_show_gotocomment_button ? "" : "style='display: none;'"  aria-label="Comment" tooltip="评论">
		<span class="btn-inner--icon"><i class="fa fa-comment-o"></i></span>
	</button>
	<button id="fabtn_toggle_darkmode" class="btn btn-icon btn-neutral fabtn shadow-sm" type="button" <-% theme.fab_show_darkmode_button ? "" : "style='display: none;'"  aria-label="Toggle Darkmode" tooltip-darkmode="夜间模式" tooltip-blackmode="暗黑模式" tooltip-lightmode="日间模式">
		<span class="btn-inner--icon"><i class="fa fa-moon-o"></i><i class='fa fa-lightbulb-o'></i></span>
	</button>
	<button id="fabtn_toggle_blog_settings_popup" class="btn btn-icon btn-neutral fabtn shadow-sm" type="button" <-% theme.fab_show_settings_button ? "" : "style='display: none;'"  aria-label="Open Blog Settings Menu" tooltip="设置">
		<span class="btn-inner--icon"><i class="fa fa-cog"></i></span>
	</button>
	<div id="fabtn_blog_settings_popup" class="card shadow-sm" style="opacity: 0;" aria-hidden="true">
		<div id="close_blog_settings"><i class="fa fa-close"></i></div>
		<div class="blog-setting-item mt-3">
			<div style="transform: translateY(-4px);"><div id="blog_setting_toggle_darkmode_and_amoledarkmode" tooltip-switch-to-darkmode="切换到夜间模式" tooltip-switch-to-blackmode="切换到暗黑模式"><span>夜间模式</span><span>暗黑模式</span></div></div>
			<div style="flex: 1;"></div>
			<label id="blog_setting_darkmode_switch" class="custom-toggle">
				<span class="custom-toggle-slider rounded-circle"></span>
			</label>
		</div>
		<div class="blog-setting-item mt-3">
			<div style="flex: 1;">字体</div>
			<div>
				<button id="blog_setting_font_sans_serif" type="button" class="blog-setting-font btn btn-outline-primary blog-setting-selector-left">Sans Serif</button><button id="blog_setting_font_serif" type="button" class="blog-setting-font btn btn-outline-primary blog-setting-selector-right">Serif</button>
			</div>
		</div>
		<div class="blog-setting-item mt-3">
			<div style="flex: 1;">阴影</div>
			<div>
				<button id="blog_setting_shadow_small" type="button" class="blog-setting-shadow btn btn-outline-primary blog-setting-selector-left">浅阴影</button><button id="blog_setting_shadow_big" type="button" class="blog-setting-shadow btn btn-outline-primary blog-setting-selector-right">深阴影</button>
			</div>
		</div>
		<div class="blog-setting-item mt-3 mb-3">
			<div style="flex: 1;">滤镜</div>
			<div id="blog_setting_filters" class="ml-3">
				<button id="blog_setting_filter_off" type="button" class="blog-setting-filter-btn ml-0" filter-name="off">关闭</button>
				<button id="blog_setting_filter_sunset" type="button" class="blog-setting-filter-btn" filter-name="sunset">日落</button>
				<button id="blog_setting_filter_darkness" type="button" class="blog-setting-filter-btn" filter-name="darkness">暗化</button>
				<button id="blog_setting_filter_grayscale" type="button" class="blog-setting-filter-btn" filter-name="grayscale">灰度</button>
			</div>
		</div>
		<div class="blog-setting-item mb-3">
			<div id="blog_setting_card_radius_to_default" style="cursor: pointer;" tooltip="恢复默认">圆角</div>
			<div style="flex: 1;margin-left: 20px;margin-right: 8px;transform: translateY(2px);">
				<div id="blog_setting_card_radius"></div>
			</div>
		</div>
		
	</div>
	<button id="fabtn_open_sidebar" class="btn btn-icon btn-neutral fabtn shadow-sm" type="button" aria-label="Open Sidebar Menu" tooltip="菜单">
		<span class="btn-inner--icon"><i class="fa fa-bars"></i></span>
	</button>
	<button id="fabtn_reading_progress" class="btn btn-icon btn-neutral fabtn shadow-sm" type="button" aria-hidden="true" tooltip="阅读进度">
		<div id="fabtn_reading_progress_bar" style="width: 0%;"></div>
		<span id="fabtn_reading_progress_details">0%</span>
	</button>
</div>

<div id="content" class="site-content">


<div class="page-information-card-container">
	
</div>

<div id="sidebar_mask"></div>
<aside id="leftbar" class="leftbar widget-area" role="complementary">
		
		<div id="leftbar_part1" class="widget widget_search card bg-white shadow-sm border-0">
			<div class="leftbar-banner card-body">
				<span class="leftbar-banner-title text-white">Xjn´s Blog</span>
				
				
			</div>
			
			
				<ul id='leftbar_part1_menu' class='leftbar-menu'>
					
				</ul>
			
			<div class="card-body text-center leftbar-search-button">
				<button id="leftbar_search" class="btn btn-secondary btn-lg active btn-sm btn-block border-0" role="button" data-toggle="modal" data-target="#argon_search_modal" >
					<i class="menu-item-icon fa fa-search mr-0"></i> 搜索
				</button>
			</div>
		</div>
		<div id="leftbar_part2" class="widget widget_search card bg-white shadow-sm border-0">
			<div id="leftbar_part2_inner" class="card-body">
				
				<div class="nav-wrapper" style="padding-top: 5px;">
	                <ul class="nav nav-pills nav-fill" role="tablist">
						
							<li class="nav-item sidebar-tab-switcher">
								<a class="active show" id="leftbar_tab_catalog_btn" data-toggle="tab" href="#leftbar_tab_catalog" role="tab" aria-controls="leftbar_tab_catalog" no-pjax>文章目录</a>
							</li>
						
						<li class="nav-item sidebar-tab-switcher">
							<a class="" id="leftbar_tab_overview_btn" data-toggle="tab" href="#leftbar_tab_overview" role="tab" aria-controls="leftbar_tab_overview" no-pjax>站点概览</a>
						</li>
	                </ul>
				</div>
				<div>
					<div class="tab-content" style="padding: 10px 10px 0 10px;">
						
							<div class="tab-pane fade active show" id="leftbar_tab_catalog" role="tabpanel" aria-labelledby="leftbar_tab_catalog_btn">
								<div id="leftbar_catalog"></div>
								<script type="text/javascript">
									$(function () {
										$(document).headIndex({
											articleWrapSelector: '#post_content',
											indexBoxSelector: '#leftbar_catalog',
											subItemBoxClass: "index-subItem-box",
											itemClass: "index-item",
											linkClass: "index-link",
											offset: 80,
										});
									})
								</script>
								
							</div>
						
						<div class="tab-pane fade text-center" id="leftbar_tab_overview" role="tabpanel" aria-labelledby="leftbar_tab_overview_btn">
							<img id="leftbar_overview_author_image" src="/assets/img/auther.jpg" class="img-fluid rounded-circle shadow-sm" style="width: 100px;" alt="avatar">
							<h6 id="leftbar_overview_author_name">xjn819</h6>
							<nav class="site-state">
								<div class="site-state-item site-state-posts">
									<a href="/archives">
										<span class="site-state-item-count">6</span>
										<span class="site-state-item-name">文章</span>
									</a>
								</div>
								<div class="site-state-item site-state-categories">
									<a data-toggle="modal" data-target="#blog_categories">
										<span class="site-state-item-count">2</span>
										<span class="site-state-item-name">分类</span>
									</a>
								</div>      
								<div class="site-state-item site-state-tags">
									<a data-toggle="modal" data-target="#blog_tags">
										<span class="site-state-item-count">4</span>
										<span class="site-state-item-name">标签</span>
									</a>
								</div>
							</nav>
							
									<div class="site-author-links">
										
									</div>
								
							
									<div class='site-friend-links'>
										<div class='site-friend-links-title'><i class='fa fa-fw fa-link'></i> Links</div>
										<ul class='site-friend-links-ul'>
											
												<li class='site-friend-links-item'>
													<a href='https://blog.daliansky.net' rel='noopener' target='_blank'>黑果小兵的部落阁</a>
												</li>
											
												<li class='site-friend-links-item'>
													<a href='https://blog.tlhub.cn/' rel='noopener' target='_blank'>套陆的部落阁</a>
												</li>
											
												<li class='site-friend-links-item'>
													<a href='https://www.bugprogrammer.me/' rel='noopener' target='_blank'>Bugprogrammer的博客</a>
												</li>
											
												<li class='site-friend-links-item'>
													<a href='https://www.insanelymac.com/' rel='noopener' target='_blank'>InsanelyMac</a>
												</li>
											
												<li class='site-friend-links-item'>
													<a href='https://hyejeong.cn/' rel='noopener' target='_blank'>针针小站</a>
												</li>
											
										</ul>
									</div>
								
						</div>
					</div>
				</div>
			</div>
		</div>
</aside>
<div class="modal fade" id="blog_categories" tabindex="-1" role="dialog" aria-labelledby="" aria-hidden="true">
	<div class="modal-dialog modal-dialog-centered">
		<div class="modal-content">
			<div class="modal-header">
				<h5 class="modal-title">分类</h5>
				<button type="button" class="close" data-dismiss="modal" aria-label="Close">
					<span aria-hidden="true">&times;</span>
				</button>
			</div>
			<div class="modal-body">
				<a class="badge badge-secondary tag" href="/categories/Hackintosh/" rel="tag">Hackintosh <span class="tag-num">3</span></a><a class="badge badge-secondary tag" href="/categories/Hardware/" rel="tag">Hardware <span class="tag-num">3</span></a>
			</div>
		</div>
	</div>
</div>
<div class="modal fade" id="blog_tags" tabindex="-1" role="dialog" aria-labelledby="" aria-hidden="true">
	<div class="modal-dialog modal-dialog-centered">
		<div class="modal-content">
			<div class="modal-header">
				<h5 class="modal-title">标签</h5>
				<button type="button" class="close" data-dismiss="modal" aria-label="Close">
					<span aria-hidden="true">&times;</span>
				</button>
			</div>
			<div class="modal-body">
				<a class="badge badge-secondary tag" href="/tags/Hackintosh/" rel="tag">Hackintosh <span class="tag-num">3</span></a><a class="badge badge-secondary tag" href="/tags/Hardware/" rel="tag">Hardware <span class="tag-num">3</span></a><a class="badge badge-secondary tag" href="/tags/NAS/" rel="tag">NAS <span class="tag-num">3</span></a><a class="badge badge-secondary tag" href="/tags/OpenCore/" rel="tag">OpenCore <span class="tag-num">3</span></a>
			</div>
		</div>
	</div>
</div>

<div id="primary" class="content-area">
	<main id="main" class="site-main" role="main">
		
		
			
	<article class="post post-full card bg-white shadow-sm border-0 ">
	<header class="post-header text-center">
		
		<a class="post-title" href="/post/Upgrade-from-10Gbps-to-40Gbps-network.html">ZFS:从10Gbps升级到40Gbps网络</a>
		<div class="post-meta">
			
						
						<div class="post-meta-detail post-meta-detail-time">
							<i class="fa fa-clock-o" aria-hidden="true"></i>
							<time title="发布于 2023-1-8 20:27:50 | 编辑于 2023-2-28 15:57:10">2023-1-8 20:27
							</time>
						</div>
					
						
							<div class="post-meta-devide">|</div>
						
						<div class="post-meta-detail post-meta-detail-categories">
							<i class="fa fa-bookmark-o" aria-hidden="true"></i>
							<a class="post-meta-detail-catagory-link" href="/categories/Hardware/">Hardware</a>
						</div>
					
						
							<div class="post-meta-devide">|</div>
						
						<div class="post-meta-detail post-meta-detail-words">
							<i class="fa fa-file-word-o" aria-hidden="true"></i>
							11.7k 字
						</div>
					
						
							<div class="post-meta-devide">|</div>
						
						<div class="post-meta-detail post-meta-detail-readingtime">
							<i class="fa fa-hourglass-end" aria-hidden="true"></i>
							50 分钟
						</div>
					
		</div>
		
	</header>

	<div class="post-content" id="post_content">
		<h1 id="0-介绍"><a href="#0-介绍" class="headerlink" title="0 介绍"></a>0 介绍</h1><p>自TrueNAS Core更新至FreeBSD 13，它的两大免费产品Scale和Core都已经使用上了OpenZFS。既然如此，就直接转投OpenZFS用上Linux了，但考虑到之前一直使用SolarisZFS，可能会对OpenZFS的tuning不太熟悉，就小心翼翼的先使用了一下TrueNAS Scale试手。体验下来我个人不是很喜欢用K3S Containerd，也没有LXC，或者任何平替BSD Jail的东西，用着不是很舒服，等有空把这玩意换了。</p>
<blockquote>
<p>过了一周时间实在忍无可忍装回了TrueNas Core。</p>
</blockquote>
<p>家里装修时布置了2条MPO数据线的，但不知道为什么只有一条能通网络，导致我有段时间一直是NAS和MAC电脑端对端连着，用着也还行就没想太多。刚好早些时候拼车买了Mellanox SX6036，疫情闲赋在家就拿出来换了一套猫扇，NAS连接Mellanox SX6036再连接家里的10Gbps交换机Mikrotik CRS312，至此把40Gbps网络并入整个家庭内网。<br></br></p>
<h1 id="1-硬件添置"><a href="#1-硬件添置" class="headerlink" title="1 硬件添置"></a>1 硬件添置</h1><ul>
<li><p>Mellanox SX6036交换机。闲鱼差不多2000-3000左右，但是海淘Ebay大概在600-1200左右，邮费非常贵，如果有拼车最好了，需要授权才能使用以太网ETH模式，这个可以找淘宝或者Ebay上购买License或者破解，不是很贵。</p>
</li>
<li><p>HP 544+ 40Gbps ETH 56Gbps IB QSFP网卡。这个卡闲鱼加转接卡一起卖大概在80-120之间，非常便宜。便宜一般来说带来了很多坑，等下会写这张卡的踩坑记录。</p>
</li>
<li><p>Chelsio T580 40Gbps 网卡。这张卡我之前800左右买的，闲鱼现在我看有的1500，有的1000，看运气吧。此卡是唯一一张可以在MacOS下驱动的40Gbps PCIE网卡。此卡目前的驱动只支持到MacOS Big Sur。Monterey开始，苹果使用了DriverKit驱动，只能等Chelsio去做DriverKit。</p>
</li>
<li><p>AOC 40Gbps QSFP网线。这个我闲鱼买的橘色的细线，价格大概在30-50元每米，比较方便理线，如果是DAC铜缆价格会更加便宜，但实在是太粗难以梳理。对了，这类线都带了模块的，你不需要再另购入模块。如果要用IB功能，线就有点贵了，自行搜索。</p>
</li>
<li><p>Mellanox MAM1Q00A-QSA-655874-B21 QSFP to SFP+ 转接头。闲鱼价格在100-150之间。这个转接头方便你把10Gbps的SFP+DAC线的其中一个头转换成QSFP，从而将一台10Gbps交换机和40Gbps交换机相连。</p>
</li>
</ul>
</br>

<h2 id="1-1-非必选添置"><a href="#1-1-非必选添置" class="headerlink" title="1.1 非必选添置"></a>1.1 非必选添置</h2><ul>
<li><p>今年夏天实在太热了，NAS风扇只能满转来让硬盘温度稍微好一点，因此，我把原装的846机箱的4个8CM风扇卡槽换成了3个12CM的风扇卡槽，购买了3个追风者T30风扇。8CM兼顾PWM并且转速范围大，噪音低的实在太难买了，换成这款12CM的体验下来效果非常好。卡槽是找淘宝用PETG材质3D打印的。打印文件<a target="_blank" rel="noopener" href="https://www.thetylergibson.com/supermicro-846-120mm-fan-shroud/">购买链接</a> </p>
<blockquote>
<p>人家的劳动成果，免费分享并不道义。</p>
</blockquote>
<blockquote>
<p>追风者T30风扇需要拨动风扇中央的开关到Advance模式才能达到3000转。</p>
</blockquote>
</li>
</ul>
</br>

<ul>
<li><p>很早之前购买了超微SAS3的背板+SAS3的HBA卡（这个卡的小坑请看以前那篇文章），这样在20个硬盘能达到40Gbps的顺序读写，当然4k小文件就别想提高了。如果无法购买到或硬盘数量达不到，购买1-2个SSD组成Raid0，并写个脚本定期把Raid0的dataset通过<code>ZFS send</code>备份到主池的HDD中也是不错的选择。</p>
<blockquote>
<p>硬盘矿潮后，超微846的仿冒机箱在淘宝闲鱼盛行，务必辨别原装。非原装或者浪潮的846机箱，上面说的3D打印文件应该不适用的！我也没买过那些牌子，不知道那些连个电容都没的背板性能怎么样。我认为24盘原装或者浪潮SAS3 846机箱的价位应该在2500元左右。可怕的是我还见过机箱是原装的，电源背板全是仿冒的，请务必辨别。<br>我的NAS RAID是两组10盘Z2，并把两组Z2 Stripe为一组，可以说是Raid60。另外四个盘位随便放了两个ZFS Hot Spare盘热备换用。</p>
</blockquote>
</li>
</ul>
<ul>
<li>选购！ ATTO ThunderLink 40Gbps NQ3402 雷电网卡。这张卡是目前唯一一张支持到40Gbps并且受到最新MacOS支持的雷电网卡。价格太贵就提一嘴。这张卡其实只能跑20Gbps，因为雷电的数据传输本身只有20GB。</br>
</br>


</li>
</ul>
<h1 id="2-管理SX6036"><a href="#2-管理SX6036" class="headerlink" title="2 管理SX6036"></a>2 管理SX6036</h1><p>通过RJ45网线连接交换机的mgt口，登陆其后台IP即可管理。若你不知道管理口IP，需要用Console线（RJ45 to USB）连接，进入向导模式设置管理口IP等，这个可以看官网的说明书，这里不细说这些没用的了，说一下几个小坑。</p>
<p>如果使用SFP光缆配合购物清单中的SFP to QSFP转换头，连接10Gbps交换机和SX6036，请在后台的WEB UI中将连接口的速率手动协商至10Gbps，不然无法通信。<br>如果你有一条QSFP一分四SFP的线，需关闭其中一个口才能使用。例如，我关闭了SX6036的1口，再在ssh管理界面中对4口标注为1分4，则4口可以插入这条QSFP一分四SFP的线，具体请查阅说明书来找到关闭对应口。记不清这些操作到底是ssh就行，还是一定要console，这里还是推荐买个console线，也不贵。</p>
</br>
</br>

<h2 id="2-2-更换SX6036交换机的风扇"><a href="#2-2-更换SX6036交换机的风扇" class="headerlink" title="2.2 更换SX6036交换机的风扇"></a>2.2 更换SX6036交换机的风扇</h2><p>此款交换机有一个可灵活拆卸的风扇盒，风扇盒中有4个4CM的风扇；电源中有一个4CM的风扇，所有的风扇都是PWM的。我购买了5个猫头鹰NF-A4x20 FLX 3pin风扇，因为我觉得只要接地线和12v电源两个pin就够了，这风扇满转都听不到声音，我更加不会有心思登录到SX6036的后台通过CLI更改风扇转速。<br>原装风扇接口不是像主板上一样的4pin，风扇盒的4pin定义如下：</p>
<table>
<thead>
<tr>
<th align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;颜色&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</th>
<th align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;定义&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</th>
</tr>
</thead>
<tbody><tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;红&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;+12v&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;蓝&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;RPM&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;黄&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;PWM&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;黑&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Black GND&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
</tbody></table>
<p>我只把FLX版本猫头鹰的红黑两根针接上去了；如果你购买了PWM版本的猫头鹰A4风扇，这款猫扇的4pin定义如下：</p>
<table>
<thead>
<tr>
<th align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;颜色&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</th>
<th align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;定义&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</th>
</tr>
</thead>
<tbody><tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;蓝&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;PWM&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;绿&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;RPM&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;黄&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;+12v&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;黑&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Black GND&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
</tbody></table>
<p>更换PSU电源风扇请自行考虑安全性！！个人主观认为300W的电源换个风扇问题不大，不做参考依据！电源上4pin定义如下：</p>
<table>
<thead>
<tr>
<th align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;颜色&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</th>
<th align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;定义&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</th>
</tr>
</thead>
<tbody><tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;蓝&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;PWM&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;黄&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;RPM&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;红&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;+12v&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
<tr>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;黑&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
<td align="center">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Black GND&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</td>
</tr>
</tbody></table>
<blockquote>
<p>猫头鹰风扇和PSU的螺丝孔大小不一样，我用自带的橡皮固定了，见效果图。<br>此电源好像有其他几个版本，最好用万用表自己对照一下。</p>
</blockquote>
<p>若使用PWM的风扇可以在SSH或者Console界面输入如下命令来控制转速：</p>
<pre><code class="bash">enable  #进入高级模式
fae mlxi2c set_fan set_fan /FAN/FAN 1 65    #1代表FAN 1; 65为转速
fae mlxi2c set_fan set_fan /PS1/FAN 1 65</code></pre>
<blockquote>
<p>更换风扇后，sx6036的指示灯变红，不影响使用。若觉得不舒服，写个定时脚本，通过可以带密码的sshpass去后台清理掉关于风扇相关的报错。</p>
</blockquote>
<p>效果图：<br><img class="lazyload lazyload-style-1" src="data:image/svg+xml;base64,PCEtLUFyZ29uTG9hZGluZy0tPgo8c3ZnIHdpZHRoPSIxIiBoZWlnaHQ9IjEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgc3Ryb2tlPSIjZmZmZmZmMDAiPjxnPjwvZz4KPC9zdmc+"  data-original="https://s2.loli.net/2023/01/08/EpQUks3IynWcbrd.jpg" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAANSURBVBhXYzh8+PB/AAffA0nNPuCLAAAAAElFTkSuQmCC" alt="IMG_4217.jpg"></p>

<p> 待传…..</p>
<h1 id="3-网卡过坑"><a href="#3-网卡过坑" class="headerlink" title="3 网卡过坑"></a>3 网卡过坑</h1><p>说一下HP 544+和Chelsio T580这两张卡。</p>
<h2 id="3-1-HP-Mellanox-544"><a href="#3-1-HP-Mellanox-544" class="headerlink" title="3.1 HP Mellanox 544+"></a>3.1 HP Mellanox 544+</h2><p>如果你不太想折腾，请购买原装原厂的Mellanox卡，最好是还在维护的Mellanox 4代以上。我买了两张，说明一下情况，我的NAS和计算是彻底分开的两台机器，NAS是真的只做存储，而乱七八糟玩的是一台Proxmox VE，因此买两张分别给两台机器。<br>HP544+这张卡是Mellanox CX354a-FCCT的套娃卡，并不能刷入原装固件。HPE官网最新的固件在TrueNas使用的话，必须把此网卡的SR-IOV功能关闭，不然可能连开机都开不了。</p>
<pre><code class="bash">mstconfig -d 03:00.00 set SRIOV_EN=0</code></pre>
<blockquote>
<p>通过BIOS Legacy模式在开机引导此固件Rom的时候也可以直接进入Setup界面关闭SR-IOV，这样无需安装别的软件来设置</p>
</blockquote>
<p>暂时不懂怎么在TrueNAS下修改一些内核相关的东西，并且SR-IOV在我的TrueNAS主板上不是必需品，如果你会用，则刷入下面的老固件。</p>
<p>我在Proxmox VE中习惯使用SR-IOV，请到HPE官网下载并刷入<code>fw-ConnectX3Pro-rel-2_40_5072-764285-B21_Ax-CLP-8025-UEFI-14.11.42-FlexBoot-3.4.747.bin</code>这个老版本固件。<br>即便你使用普通的Linux发行版，驱动都已经deprecated了，插上后可以上网之类的，但是如果你想使用更高级的功能，可能需要下载Nvidia的OFED驱动进行编译。这个驱动看样子也不会再更新了，不知道哪天还能不能编译出来。下载对应的OFED编译，方式跟下面Chelsio的差不多就不写了。另外通过我的观察，即便IOMMU分组已经分开两个口的IRQ了，但是PCI地址还是一个，所以无法将两个口分别直通给两个不同的VM Guests。如果可以，请告知。</p>
</br>
</br>

<p>尽管搜索国外论坛提示如果不用OFED可能会在使用SR-IOV或者Pause帧中遇到问题，我这两天还是试用tree上自带的驱动并使用SR-IOV，只是发现了windows虚拟机上的VF有个小问题，下面给了解决方案了，别的没碰到啥问题。我没有编译过OFED，随便看了一下好像还行，但是能用tree上的驱动就不想动了。<br>安装<code>mstflint</code>,以Proxmox VE为例：</p>
<pre><code class="bash">apt update &amp;&amp; apt install mstflint</code></pre>
<p>通过<code>lspci</code>获得Mellanox网卡的设备号并设置，例如：</p>
<pre><code class="bash">lspci |grep Mellanox

03:00.0 Ethernet controller: Mellanox Technologies MT27520 Family [ConnectX-3 Pro]

mstflint -d 03:00.00 query   #获得固件信息
mstflint -d 03:00.00 -i 固件路径 b  #刷入固件
mstconfig -d 03:00.00 query    #获取设备设置信息
mstconfig -d 03:00.00 set SRIOV_EN=1 NUM_OF_VFS=8  #开启SR-IOV以及设置VF总数为8个；确保主板已开通sr-iov，Proxmox VE已开通虚拟化等设置
mstconfig -d 03:00.00 set LINK_TYPE_P1=ETH  #设置p1端口为ETH模式</code></pre>
<p>创建一个/etc/modprobe.d/mlx4_core.conf填入：</p>
<pre><code class="bash">options mlx4_core port_type_array=2,2 num_vfs=4,0,2 probe_vf=4,0,2</code></pre>
<ul>
<li>port_type_array=2,2 意味着两个端口都是ETH模式</li>
<li>num_vfs 是VF数量，格式是a,b,c。a和b分别代表端口1和2的VF量，而C是总量。注意C不是<code>a+b</code>，而是a和b的数量去掉PF数量。</li>
<li>probe_vf 格式同上；为Proxmox下ip link中能得到的数量</li>
<li>这里我让第一个口做了4个VF给各种虚拟机和LXC用，第二个口不动我拿来给PVE用了。</li>
</ul>
<p>设置完后记得<code>update-initramfs -u</code>后重启。</p>
<p>创建一个shell，assign mac地址以及vf link up:</p>
<pre><code class="bash">nano /opt/sr-iov.sh</code></pre>
<p>内容如下</p>
<pre><code class="bash">#!/bin/sh
ip link set dev enp2s0 mtu 9000  #这个你看自己需求是否要设置mtu。如果pf是1500，那么vf设置9000会有问题。
ip link set dev enp2s0 vf 0 mac ae:51:1a:2b:c0:00
ip link set dev enp2s0 vf 1 mac ae:51:1a:2b:c0:01
ip link set dev enp2s0 vf 2 mac ae:51:1a:2b:c0:02
ip link set dev enp2s0 vf 3 mac ae:51:1a:2b:c0:03
ip link set enp2s0 up
ip link set enp2s0v0 up
ip link set enp2s0v1 up
ip link set enp2s0v2 up
ip link set enp2s0v3 up</code></pre>
<p>记得<code>chmod +x /opt/sr-iov.sh</code></p>
<p>创建systemd unit开机运行</p>
<pre><code class="bash">nano mlx-sr-iov.service</code></pre>
<p>内容如下</p>
<pre><code class="bash">[Unit]
Description=Script to enable MLX SR-IOV

[Service]
Type=oneshot
ExecStart=/opt/sr-iov.sh

[Install]
WantedBy=multi-user.target</code></pre>
<p>创建完后<code>systemctl enable mlx-sr-iov.service</code></p>
</br>
</br>

<p>如果要用Windows的VM，则尽可能使用Windows的LTSC版本。在PVE内核大于Linux 5.13的情况下，使用3代网卡的VF直通到Windows你要对Proxmox的kernel进行patch，不然Windows Guest的设备管理器里，这个VF会报错code 43。具体参考<a target="_blank" rel="noopener" href="https://forums.servethehome.com/index.php?threads/help-with-connectx-3-sr-iov-with-linux-host-and-windows-guest-via-kvm.28956/page-1">这里</a>。 有空我把我自己patch好的传到Github上去。当然不使用tree上的驱动，在Proxmox上安装OFED驱动也可以解决，但是3代卡的OFED驱动也就只支持到5.13的内核，还是要自己编译驱动，自己选哪条路简单。最后一种办法是安装proxmox-ve_7.1-2.iso这个版本，然后pin内核。</p>
<pre><code class="bash">uname -a #查看内核版本
apt update
apt search pve-kernel|grep pve-kernel- #查看可以安装的内核
apt install pve-kernel-5.xxxxxx-pve #安装特定版本内核，当然初次安装的是新的内核切回去旧的太麻烦了，还不如重装。
proxmox-boot-tool kernel list #查看pve下已经有的内核
proxmox-boot-tool kernel pin 5.13.19-6-pve #pin住内核</code></pre>
<blockquote>
<p>说实在的，Windows我都懒得用。都不知道Windows怎么跑40Gbps，文件管理器是单线程的，SMB是单线程的，ISCSI在较新的windows 10版本中也是单线程的=。=。RDMA？跟这篇文章主题无关。</p>
</blockquote>
</br>


<p>我别的虚拟机全是LXC，很方便通过PF或者VF。通过修改/etc/pve/lxc/xxx.conf文件，加入你想要通过去的VF即可了：</p>
<pre><code class="bash">lxc.net.1.type: phys
lxc.net.1.flags: up
lxc.net.1.link: enp3s0v0
lxc.net.1.hwaddr: ae:54:1c:2b:c0:00
lxc.net.1.name: eth11
lxc.net.0.type: phys
lxc.net.0.flags: up
lxc.net.0.link: enp3s0v1
lxc.net.0.hwaddr: ae:54:1c:2b:c0:01
lxc.net.0.name: eth2

####下面这部分是我的NixOS LXC使用proxmox主板的核心显卡，跟主题无关，当个小彩蛋吧。
lxc.cgroup2.devices.allow: c 226:0 rwm
lxc.cgroup2.devices.allow: c 226:128 rwm
lxc.cgroup2.devices.allow: c 29:0 rwm
lxc.mount.entry: /dev/dri dev/dri none bind,optional,create=dir
lxc.mount.entry: /dev/fb0 dev/fb0 none bind,optional,create=file
lxc.autodev: 1
lxc.hook.autodev: sh -c &quot;chmod -R 666 /dev/dri/card*; chmod -R 666 /dev/dri/render*&quot;</code></pre>
<blockquote>
<p>我通两个VF是因为有一个eth11我是给transmission下载PT用的，transmission的config.json中可以设置<code>bind-address-ipv4</code>，这样我在路由器上就可以更方便的管理transmission.,e.g.定时限速，是否走特殊的流量代理。</p>
</blockquote>
</br>
</br>

<h2 id="3-2-Chelsio-T580"><a href="#3-2-Chelsio-T580" class="headerlink" title="3.2 Chelsio T580"></a>3.2 Chelsio T580</h2><p>Chelsio对FreeBSD的支持特别好，我想因此他们也愿意做一下MacOS的驱动。这张卡在linux下的驱动比较麻烦，随手写一下我在 Proxmox VE 7下面驱动此卡的方法：</p>
<ul>
<li><p>从官网下载最新版的tar.gz压缩包</p>
</li>
<li><p>解压压缩包<code>tar -zxvf ChelsioUwire-x.xx.x.x.tar.gz</code></p>
</li>
<li><p>安装rpm <code>sudo apt install rpm</code></p>
</li>
<li><p>安装pve的linux headers </p>
<pre><code class="bash">sudo apt install pve-headers-`uname -r`</code></pre>
</li>
<li><p>确认你kernel sources的路径，应该是<code>usr/src/linux-headers-x.xx.xx-x-pve/</code></p>
</li>
<li><p>回到刚才解压缩好的文件夹里，修改Makefile:</p>
<pre><code class="bash">DEBIAN := 1
PDEB := 1
DISTRO := Debian</code></pre>
</li>
<li><p>在当前目录编译驱动 <code>make KDIR=/usr/src/linux-headers-x.xx.xx-x-pve/</code></p>
</li>
<li><p>完成后你可以使用此卡的高级功能 e.g.SR-IOV, etc.</p>
</li>
<li><p>每次更新PVE内核你都需要重新编译驱动。</p>
</li>
</ul>
</br>
</br>

<h3 id="3-2-1-Chelsio-T580在MacOS下的驱动"><a href="#3-2-1-Chelsio-T580在MacOS下的驱动" class="headerlink" title="3.2.1 Chelsio T580在MacOS下的驱动"></a>3.2.1 Chelsio T580在MacOS下的驱动</h3><p>这张卡直接在官网下载驱动安装就行，最高只支持到Big Sur，如遇签名过期，断网修改本地时间。<br>如果你希望干净一点安装，在MacOS下通过命令<code>pkgutil --expand-full [pkg] [dir]</code>获得PKG内的KEXT。其中cxgb.kext是Chelsio T580的驱动，cxgb3.kext是T3xx系列的驱动。</p>
<ul>
<li>下载<a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/OCNHTeam/OCNHTeam.github.io/main/tools/cxgb.kext.zip">cxgb.kext</a></li>
</ul>
<p>如果是黑苹果，你可以通过OpenCore直接加载kext。</p>
<ul>
<li>这个卡超级超级超级热！温度过高会导致掉光模块或者掉卡。一个风扇不够，你需要2-4个风扇全面覆盖它才可以；条件允许，水冷。<blockquote>
<p>注意，拆卸此卡时小心灼伤！</p>
</blockquote>
</li>
</ul>
</br>
</br>


<h1 id="4-OpenZFS"><a href="#4-OpenZFS" class="headerlink" title="4 OpenZFS"></a>4 OpenZFS</h1><p>对于FreeBSD而言，SolarisZFS和OpenZFS使用上差别不是那么大。但是在Linux上实现OpenZFS我暂时没明白，OpenZFS的实现固然很有用，但是在BSD里物理硬盘与VDEV是依赖于Geom去实现的，Geom提供<code>providers</code>给OpenZFS来做成Vdevs，则完成整一套的虚拟-物理设备之间的通信。因不懂没了Geom怎么实现block的<code>check sum</code>和<code>data healing</code>，既然不懂，我就不用了吧。</p>
</br>
</br>

<h2 id="4-1-Ashift"><a href="#4-1-Ashift" class="headerlink" title="4.1 Ashift"></a>4.1 Ashift</h2><p>Ashift是设置物理硬盘的<code>Block size</code>的。例如，Seagate EXOS 16T的7200转SATA机械硬盘默认是一个logic sector默认为512B，physcial sector默认是4k。在老的FreeNAS版本中，通过UI建立存储池默认给的Ashift是9，代表着512B。而现代的TrueNAS默认给的是0，代表自动辨别。一般来说，设置成9(512B)会带来一个问题：写入一个4K文件，它会切割成8份，那会对服务器带来一定的压力，但尽量减少空间损失。而如果设置成更大，则会浪费空间。书籍中建议设置成Ashift=12，则是block size=4k。这样会尽力减小服务器压力，而浪费的空间则可以通过compression来减少损失。通过如下命令确认自己的Ashift：</p>
<pre><code class="bash">zpool get all PoolName |grep ashift</code></pre>
<blockquote>
<p>为什么是9和12? 2^9=512;2^12=4096。一些新的SSD已经到了8k，则ashift=13</p>
</blockquote>
</br>
</br>


<h2 id="4-2-Meta-Vdevs"><a href="#4-2-Meta-Vdevs" class="headerlink" title="4.2 Meta Vdevs"></a>4.2 Meta Vdevs</h2><p>Meta Vdevs是近几年新出的一个功能。这个Vdev并不是一个缓存，而是一个Storage，因此，你需要确保这个Vdev有较高的安全性，比如两个optane硬盘组成一个Mirror甚至更大的冗余，如果这组Vdev坏了，在同一个Pool下的机械池数据也同样丢失。请不要想着<code>试试看能不能用</code>，操作不可逆。</p>
</br>

<p>Meta Vdevs解决了两个问题。</p>
<ul>
<li>如果你的存储池存在很多小文件，那读取或者写入都会牵扯到机械硬盘的stroke时间,io depth,queue等问题。那么，如果把pool的<code>Metadata</code>放在了Optane上，则至少可以减少storke的时间，也能收获到更多的IO queues，这对小文件多线程是很有帮助的。</li>
<li>你同样可以对Meta Vdev进行设置：把特定的<code>Block size</code>文件存于Optane中，而没有命中规则的文件，则放入原来的机械存储池中。<br>TrueNas的Pool–dataset–option中，可以看到你对这个池的<code>Record size</code>，比如我的是128K，然后我在下面的<code>Metadata (speical) small block size</code>中设置一个值，比如是64k。当一个文件≤ 64k，则自动存入Optane中。当<code>Metadata (speical) small block size</code>=<code>Record size</code>，则所有文件全会存入Optane中，显然这样做，还不如单独用Optane建立一个池。<br>在看<code>Meta Vdevs</code>的手册时，我思考了如下两个问题：</br>

</li>
</ul>
<h3 id="Optane作为Meta-Vdev存满了，我该怎么办？"><a href="#Optane作为Meta-Vdev存满了，我该怎么办？" class="headerlink" title="Optane作为Meta Vdev存满了，我该怎么办？"></a>Optane作为Meta Vdev存满了，我该怎么办？</h3><p>根据手册的说法，Meta Vdev存满了，则会根据算法自动将使用频率少的文件回落到机械硬盘。<br></br></p>
<h3 id="我应该选择多大的Optane来存放？"><a href="#我应该选择多大的Optane来存放？" class="headerlink" title="我应该选择多大的Optane来存放？"></a>我应该选择多大的Optane来存放？</h3><p>我们可以看一下你之前的一些比较具有代表性的小文件池来观察估算:</p>
<pre><code class="bash">cd /mnt/poolname/test #cd到你想测试的dataset下
find . -type f -print0 | xargs -0 ls -l | awk &#39;&#123; n=int(log($5)/log(2)); if (n&lt;10) &#123; n=10; &#125; size[n]++ &#125; END &#123; for (i in size) printf(&quot;%d %d\n&quot;, 2^i, size[i]) &#125;&#39; | sort -n | awk &#39;function human(x) &#123; x[1]/=1024; if (x[1]&gt;=1024) &#123; x[2]++; human(x) &#125; &#125; &#123; a[1]=$1; a[2]=0; human(a); printf(&quot;%3d%s: %6d\n&quot;, a[1],substr(&quot;kMGTEPYZ&quot;,a[2]+1,1),$2) &#125;&#39;
</code></pre>
<p>看一下你的这个dataset下文件的整个block size分布，按比例预估。<br>另外通过如下命令也可以看到整个pool的情况，除掉<code>L0 Total</code>外的总和就是你的metadata目前所需要的空间。具体的一些估算以及应用方法请参考<a target="_blank" rel="noopener" href="https://forum.level1techs.com/t/zfs-metadata-special-device-z/159954">这里</a>。当然，我们讨论的文件大小都是通过compression压缩后的大小。非Optane的SSD作为Meta Devs你需要手动开启<code>trim on</code>。</p>
<pre><code class="bash">zdb -LbbbA -U /data/zfs/zpool.cache &lt;poolname&gt;</code></pre>
</br>

<p>最后有个小问题，metadata对于Zvol是无用的。对ZFS来说，往zvol写入多少文件都只是<code>block size</code>大小完全一样的存在，你可以收益到的只是Metadata对Zvol的加速。这个问题的讨论请参考<a target="_blank" rel="noopener" href="https://github.com/openzfs/zfs/discussions/12769">这里</a>。如果你是zvol用的频繁并且还需要更极致的zvol性能，参考章节6.ZFS Send。<br></br><br></br></p>
<h2 id="4-3-Dedup-Vdevs"><a href="#4-3-Dedup-Vdevs" class="headerlink" title="4.3 Dedup Vdevs"></a>4.3 Dedup Vdevs</h2><p>一般来说，开启了dedup功能的dataset能做到文件去重复的作用，也就是多个一模一样的文件只占用一份文件的容量。以前用内存来做，代价是用内存换硬盘空间，现在即便是可以用Dedup Vdev来换机械硬盘空间，也不推荐。Meta Vdevs存储了dedup datasheet，同样做到了dedup功能，不如用meta dev。<br>开启dedup的dataset是不可逆的，请把已经开启dedup的dataset通过<code>zfs send</code>到新的dataset里，再删除旧的。名字的话通过<code>zfs rename</code>改回来。<br></br><br></br></p>
<h2 id="4-4-Slog"><a href="#4-4-Slog" class="headerlink" title="4.4 Slog"></a>4.4 Slog</h2><p>如果说起ZFS的写缓存，往往会被误导到使用Slog，这里可以明确指出，Slog不会让你的写入速度超过当你dataset设置成async的速度的。ZFS在写入时先产生ZFS intent log(ZIL)，也就是未来会写入的文件的一个操作日志，在5秒为预期的时间内，文件会先进入内存(TXG)，再写入硬盘，当整个文件还没落盘，文件不具备可读性以及可执行性的情况下，我们称之为脏数据(dirty data)，最后等落盘写入，整个操作完成，而这个文件通过判断可能会继续留在内存的ARC里作为未来的读缓存。我们看下来整个过程，其实ZFS并不具备传统意义上的写缓存，而是一个缓冲区为未来的读取做准备的。</p>
<p>另一方面这样的写入是异步操作的，在更严谨的环境中，需要同步写入(sync write)。同步写入的速度会非常慢，通过增加Slog，比如Optane这种写入快，安全性高的硬盘去帮我们提高写入速度，当然，当Optane开启了FUA bit作为Slog后，速度也不会太好看的。<br>总之，Slog只是保证了你文件的同步写入，家用情况，UPS足矣。<br></br><br></br></p>
<h2 id="4-5-L2arc"><a href="#4-5-L2arc" class="headerlink" title="4.5 L2arc"></a>4.5 L2arc</h2><p>本来就想写一点点的。。为嘛我越写越多。。<br></br><br></br></p>
<h2 id="4-6-HDD-Storage-Pool"><a href="#4-6-HDD-Storage-Pool" class="headerlink" title="4.6 HDD Storage Pool"></a>4.6 HDD Storage Pool</h2><p>TrueNAS通过WebUI建立的pool非常平庸，如果你对自己的硬盘参数性能非常了解，请通过zfs命令建立。</p>
<p>有空再写。</p>
<h2 id="4-7-OpenZFS-tuning"><a href="#4-7-OpenZFS-tuning" class="headerlink" title="4.7 OpenZFS tuning"></a>4.7 OpenZFS tuning</h2><p>ZFS 的使用优化是没有参照的，即便是跟我买完全一模一样的机器，拿回去使用场景不同都不能tuning一样的。老老实实看OpenZFS的Manual吧，没有捷径。但我可以说一下我自己的一些40Gbps网路下的Tuning思路。</p>
<ul>
<li>在内存<font color="#660000">有限</font>的情况下使用<code>L2arc</code>提高读取速度。<code>L2arc</code>是一个高性价比的选择。在内存arc仍然growing的情况下强行使用l2arc只会让你的读取速度变慢，按现代计算机架构来看，没有啥SSD是比内存更快的。</li>
<li><code>L2arc</code>的容量尽可能匹配内存<code>arc</code>容量的4-5倍之间，超过容量后的那部分tuning不切实际。</li>
<li><code>dirty data</code>的设置需要花时间观察的，因为不同场景下的值不是一样的，也不是越大越好，需要花费大量时间观察调整，再观察调整循序渐进，没吃太饱的话还是保持默认吧。</li>
<li>慎重考虑<code>Meta Devs</code>这个功能。</li>
<li>最后提一嘴，所有的Tuning都是有代价的。</li>
</ul>
</br>
</br>

<h1 id="5-NFS-Tuning"><a href="#5-NFS-Tuning" class="headerlink" title="5 NFS Tuning"></a>5 NFS Tuning</h1><p>NFS对于小文件的读写是不理想的，有条件的话尽可能使用iSCSI。<br>NFS Version ≥ 4.1，并且在NFS Server 设置中把线程设置成24个或者更高（看你CPU），链接NAS是可以大文件跑满40Gbps的。如果是4k小文件请调小NAS服务端的<code>Block Size</code>，同样客户端的<code>wsize</code> <code>rsize</code>都理应调小。另外MTU 9000对于4k是很有用的，条件允许，开启。<br>MacOS依然没有更新NFS版本，并且在Finder下因为<code>Foundation API</code>通过版本<code>NFS v4.0</code>连接NAS会出现断连的情况，而在MacOS的Terminal中使用POSIX权限则没有这样的现象。<br>但在MacOS中，无论使用什么40Gbps卡，你都只能在GUI界面环境中获得20Gbps的连接速度，这也许是因为协议层太过老旧而用户无从选择。</p>
<p>如果是Samba的话，我无法给出一个标准答案，这完全取决于你CPU的单核心能力，毕竟只有上传和下载两个线程。又或者说你希望使用<code>SMB Multi-Channels</code>功能来解决这个问题。</p>
<blockquote>
<p>话说回来，微软那边已经支持SMB作为服务端（也就是你必须用Win Server）而客户端用新的社区Samba版本，也可以多线程了。不知道微软和Samba弄到啥时候去，太畸形了，作为用户我唯一的权利就是选择不用。</p>
</blockquote>
<h1 id="6-ZFS-Send"><a href="#6-ZFS-Send" class="headerlink" title="6 ZFS Send"></a>6 ZFS Send</h1><p>机械SATA硬盘无法与现代的SSD比肩4k类的读写，尤其是在<code>IO Depth</code> <code>IOPS</code>等方面。如果你不满足于<code>Meta devs</code>功能来提高4k的写入和读取，单独使用了一块SSD硬盘做日常的使用，并且设置了<code>ZFS Send</code>按天甚至按小时回传数据到HDD池中。</p>
<pre><code class="bash">zfs send SSD/works@3 | zfs recv Home/test</code></pre>
<p><code>ZFS Send</code>必须先建立快照，其中<code>3</code>代表快照名，而后的Home/test则为机械硬盘池。同样，你可以使用TrueNas Web UI中自带的<code>Replication Task</code>来完成类似的操作。</p>
<h1 id="7-Proxmox-VE-ZFS-over-iSCSI"><a href="#7-Proxmox-VE-ZFS-over-iSCSI" class="headerlink" title="7 Proxmox VE ZFS over iSCSI"></a>7 Proxmox VE ZFS over iSCSI</h1><p>在设置好TrueNAS的ZFS Pool后，另一台负责计算的Proxmox VE则不需要硬盘了。考虑无盘启动的话，可以参考很多IPXE教程，当然如果是超微主板或者Mellanox网卡可以直接使用Booting over iSCSI。超微的BIOS中直接有这个选项，Mellanox网卡的话使用它的<code>Flexboot</code>功能就可以了。<br>除了启动盘外，那各个VM Guest则需要开启Proxmox VE的<code>ZFS over iSCSI</code>功能。在PVE的<code>Datacentre</code>–<code>Storage</code>—<code>Add</code>中添加。</p>
<blockquote>
<p>这个<code>ZFS over iSCSI</code>其实和真正的还不一样，说白了只是一个远程的Zvol管理功能。</p>
</blockquote>
<p>这里并没有可支持TrueNAS的<code>iSCSI Provider</code>。你需要使用<a target="_blank" rel="noopener" href="https://github.com/TheGrandWazoo/freenas-proxmox">这个</a>插件来连接TrueNAS。</p>
<blockquote>
<p>这个插件的<code>API Password</code>就是root的登陆密码，不是<code>API Key</code>。</p>
</blockquote>
<p>使用<a target="_blank" rel="noopener" href="https://github.com/Corsinvest/cv4pve-autosnap">这个</a>工具可以对VM Guest自动化操作snapshot。这里的快照是使用<code>ZFS Snapshot</code>的，可以完全利用到ZFS的功能了。链接中有好多个视频操作演示教程，这里就不赘述了。</p>
<h1 id="8-IP-over-Infiniband"><a href="#8-IP-over-Infiniband" class="headerlink" title="8 IP over Infiniband"></a>8 IP over Infiniband</h1><p>Proxmox VE和TrueNAS都支持IP over Infiniband(IPoIB)。这里最好买原装的Mellanox 56GB FDR QSFP+铜缆，别的牌子可能兼容性没有这么好，闲鱼大概2米的在100元左右（线比网卡贵系列）。</p>
<p>首先最好找一台机器把两张HP 544+的卡的其中一个口刷成IB mode，TrueNAS系统下是无法操作的。</p>
<pre><code class="bash">lspci |grep Mellanox
03:00.0 Ethernet controller: Mellanox Technologies MT27520 Family [ConnectX-3 Pro]
mstconfig -d 03:00.00 set LINK_TYPE_P1=IB LINK_TYPE_P2=ETH #设置p1端口为IB模式</code></pre>
<p>这里假设p1口是IB模式，p2口是ETH模式。</p>
<ul>
<li><p>SX6036<br>在SX6036的WebUI下切换profile到vpi模式，然后在端口管理处修改端口类型。我这里把1-21口设置成了ETH模式，22-36口为IB模式。<br>在IB SM Mgmt菜单中找到base SM，选择SM Enabled来开启SM。注意，这些设置完后都要按右上角的SAVE按钮，不然重启就失效了。</p>
</li>
<li><p>PVE端<br>输入<code>modprobe ib_ipoib</code>加载ipoib的驱动，然后通过<code>ip a</code>看到加载的ib口了，一般就是叫<code>ibp2s0</code>或者<code>ibp2S0d1</code>。<br>修改/etc/network/interfaces</p>
<pre><code class="bash">auto ibp2s0
iface ibp2s0 inet static
     address  10.99.0.1
     netmask  255.255.255.0
     pre-up modprobe ib_ipoib
     pre-up echo connected &gt; /sys/class/net/ibp2s0/mode
     mtu 65520</code></pre>
<p>自己修改网卡名字，注意，这里面的网端不能跟你eth网段相同的。最后输入<code>systemctl restart networking.service</code>生效，我们可以看到SX6036交换机的管理界面中已经有IB流量出现了。</p>
</li>
<li><p>TrueNAS端<br>在Core的BSD分支中，直接在Tunables中增加一条:</p>
<pre><code class="xml">mlx4ib_load 
Value: YES
type: loaders</code></pre>
<p>并在Tasks/Init/Shutdown Scripts中增加一条postinit 命令：</p>
<pre><code class="bash">kldload ipoib</code></pre>
<p>最后如同设置普通网卡的ip地址一样，在webui中设置与PVE同一段的ip，比如10.99.0.2/24。这里有个小问题就是Core版本的MTU到底怎么改到65520，我没弄明白，不行的话，两端全部改成MTU=2044。</p>
<p>如果是Scale版本的话，插上网卡在WebUI上啥都别设置，输入<code>modprobe ib_ipoib &amp;&amp; modprobe ib_umad</code>后，你通过<code>ls /sys/class/net</code>就能知道你IB口的名字了，接着直接修改/etc/network/interfaces</p>
<pre><code class="bash">auto ibs1d1
iface ibs1d1 inet static
     address  10.99.0.2
     netmask  255.255.255.0
     pre-up modprobe ib_ipoib &amp;&amp; modprobe ib_umad
     pre-up echo connected &gt; /sys/class/net/ibs1d1/mode
     mtu 65520</code></pre>
<p>保存重启就好了。</p>
</li>
</ul>
</br>
</br>

<h1 id="9-性能测试"><a href="#9-性能测试" class="headerlink" title="9 性能测试"></a>9 性能测试</h1><p>感觉说了这么多，最终还是要测一下的，但是坦率的说，我很讨厌跑这些东西，因为跟实际使用环境差太多了，参考价值比较低。真的要测，还是要用你的常用软件，协议等等方面一起去看一下表现的。</p>
<p>配置如下：</p>
<ul>
<li>TrueNas Server配置：<ul>
<li>CPU:E5-2680 v3</li>
<li>主板: 超微X10-SRA-F</li>
<li>内存：SK海力士HMA82GR7CJR8N-VK DDR4 Reg ECC 2666 16G x8</li>
<li>机械硬盘：16T Seagate EXOS x 10 + 12T Seagate EXOS x10；两组RaidZ2后stripe，已经用了54%的容量了，其实有几个是酷狼pro，我记不得是多大的在哪组里了，反正没啥区别。</li>
<li>NVME：480G Optane 905P x1 + 480G Samsung 983zet x1；组成mirror后放在了同一组机械池作为Meta Dev。</li>
<li>网卡：HP 544+；最新固件，ETH模式，关闭了SR-IOV。</li>
<li>SAS卡：LSI 9300-8i</li>
<li>背板：超微BPN-SAS3-846EL1</li>
<li>系统：TrueNAS-13.0-U3.1</li>
</ul>
</li>
<li>Proxmox VE Client 配置：<ul>
<li>CPU：E-2186G</li>
<li>主板：超微X11-SCA-F</li>
<li>内存：Samsung DDR4 UDIMM ECC 2666 16G x8</li>
<li>机械硬盘：无</li>
<li>NVME：无</li>
<li>网卡：HP 544+；老固件，ETH模式，开了SR-IOV</li>
<li>内核：Linux 6.0.15 自己patch的</li>
</ul>
</li>
</ul>
<p>在Proxmox VE下，分别虚拟化以下系统，全是vm，没测lxc，直通了SR-IOV</p>
<h2 id="IPoIB"><a href="#IPoIB" class="headerlink" title="IPoIB"></a>IPoIB</h2><p>通过IPoIB连接PVE和TrueNAS，再通过ZFS over iSCSI跑虚拟机。下面测试中10.99.0.0是IPoIB，10.10.10.0是ETH<br>通过ping测了一下latency</p>
<pre><code class="bash">PING 10.99.0.2 (10.99.0.2) 56(84) bytes of data.
64 bytes from 10.99.0.2: icmp_seq=1 ttl=64 time=0.096 ms
64 bytes from 10.99.0.2: icmp_seq=2 ttl=64 time=0.099 ms
64 bytes from 10.99.0.2: icmp_seq=3 ttl=64 time=0.099 ms
64 bytes from 10.99.0.2: icmp_seq=4 ttl=64 time=0.091 ms 
PING 10.10.10.11 (10.10.10.11) 56(84) bytes of data.
64 bytes from 10.10.10.11: icmp_seq=1 ttl=64 time=0.296 ms
64 bytes from 10.10.10.11: icmp_seq=2 ttl=64 time=0.224 ms
64 bytes from 10.10.10.11: icmp_seq=3 ttl=64 time=0.237 ms
64 bytes from 10.10.10.11: icmp_seq=4 ttl=64 time=0.254 ms</code></pre>
<p>通过qperf测试</p>
<pre><code class="bash">root@pve:~# qperf 10.99.0.2 tcp_bw tcp_lat udp_bw udp_lat
tcp_bw:
    bw  =  3.61 GB/sec
tcp_lat:
    latency  =  8.61 us
udp_bw:
    send_bw  =  7.39 GB/sec
    recv_bw  =  4.54 GB/sec
udp_lat:
    latency  =  7.85 us

root@pve:~# qperf 10.10.10.11 tcp_bw tcp_lat udp_bw udp_lat
tcp_bw:
    bw  =  4.31 GB/sec
tcp_lat:
    latency  =  11.3 us
udp_bw:
    send_bw  =   2.5 GB/sec
    recv_bw  =  2.47 GB/sec
udp_lat:
    latency  =  18.3 us</code></pre>
<h2 id="windows-10-LTSC-1809"><a href="#windows-10-LTSC-1809" class="headerlink" title="windows 10 LTSC (1809)"></a>windows 10 LTSC (1809)</h2><p>设置：</p>
<ul>
<li>分了12个CPU 20G内存, q35, cpu-host</li>
<li>虚拟机中安装了官网的最新OFED</li>
<li>MTU 9000</li>
<li>直接装的，完全没更新过任何补丁</li>
<li>Windows的系统盘是虚拟scsi且放置于zfs over iscsi之上的。因为sata的协议queue本身有限制了</li>
</ul>
<p>不是很懂windows的这些测速软件，跑出来的数据也太魔幻了，实际用各种软件限制，协议限制。最真实的还是<code>zfs over iscsi</code>，我暂时没有条件用RDMA。</p>
<h3 id="iperf3"><a href="#iperf3" class="headerlink" title="iperf3"></a>iperf3</h3><pre><code class="bash">[ ID] Interval           Transfer     Bitrate
[  5]   0.00-4.00   sec   893 MBytes  1.87 Gbits/sec                  receiver
[  8]   0.00-4.00   sec   902 MBytes  1.89 Gbits/sec                  receiver
[ 10]   0.00-4.00   sec   904 MBytes  1.89 Gbits/sec                  receiver
[ 12]   0.00-4.00   sec   875 MBytes  1.84 Gbits/sec                  receiver
[ 14]   0.00-4.00   sec   898 MBytes  1.88 Gbits/sec                  receiver
[ 16]   0.00-4.00   sec   904 MBytes  1.90 Gbits/sec                  receiver
[ 18]   0.00-4.00   sec   884 MBytes  1.85 Gbits/sec                  receiver
[ 20]   0.00-4.00   sec   900 MBytes  1.89 Gbits/sec                  receiver
[ 22]   0.00-4.00   sec   904 MBytes  1.90 Gbits/sec                  receiver
[ 24]   0.00-4.00   sec   867 MBytes  1.82 Gbits/sec                  receiver
[ 26]   0.00-4.00   sec   903 MBytes  1.89 Gbits/sec                  receiver
[ 28]   0.00-4.00   sec   896 MBytes  1.88 Gbits/sec                  receiver
[ 30]   0.00-4.00   sec   903 MBytes  1.89 Gbits/sec                  receiver
[ 32]   0.00-4.00   sec   903 MBytes  1.89 Gbits/sec                  receiver
[ 34]   0.00-4.00   sec   898 MBytes  1.88 Gbits/sec                  receiver
[ 36]   0.00-4.00   sec   882 MBytes  1.85 Gbits/sec                  receiver
[ 38]   0.00-4.00   sec   902 MBytes  1.89 Gbits/sec                  receiver
[ 40]   0.00-4.00   sec   902 MBytes  1.89 Gbits/sec                  receiver
[ 42]   0.00-4.00   sec   901 MBytes  1.89 Gbits/sec                  receiver
[ 44]   0.00-4.00   sec   900 MBytes  1.89 Gbits/sec                  receiver
[ 46]   0.00-4.00   sec   900 MBytes  1.89 Gbits/sec                  receiver
[ 48]   0.00-4.00   sec   893 MBytes  1.87 Gbits/sec                  receiver
[ 50]   0.00-4.00   sec   892 MBytes  1.87 Gbits/sec                  receiver
[ 52]   0.00-4.00   sec   899 MBytes  1.89 Gbits/sec                  receiver
[SUM]   0.00-4.00   sec  21.0 GBytes  45.1 Gbits/sec                  receiver</code></pre>
<h3 id="CrystalDiskMark"><a href="#CrystalDiskMark" class="headerlink" title="CrystalDiskMark"></a>CrystalDiskMark</h3><p>分别测了<code>ZFS over iSCSI</code>,<code>iSCSI</code>,<code>MS-SMB</code></p>
<ul>
<li>ZFS over iSCSI<br><img class="lazyload lazyload-style-1" src="data:image/svg+xml;base64,PCEtLUFyZ29uTG9hZGluZy0tPgo8c3ZnIHdpZHRoPSIxIiBoZWlnaHQ9IjEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgc3Ryb2tlPSIjZmZmZmZmMDAiPjxnPjwvZz4KPC9zdmc+"  data-original="https://s2.loli.net/2023/02/28/rI1JFL5VfQlDuqk.png" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAANSURBVBhXYzh8+PB/AAffA0nNPuCLAAAAAElFTkSuQmCC" alt="zfsoiscsi.png"></li>

</ul>
<blockquote>
<p>用的是device分享模式</p>
</blockquote>
<ul>
<li><p>iSCSI<br><img class="lazyload lazyload-style-1" src="data:image/svg+xml;base64,PCEtLUFyZ29uTG9hZGluZy0tPgo8c3ZnIHdpZHRoPSIxIiBoZWlnaHQ9IjEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgc3Ryb2tlPSIjZmZmZmZmMDAiPjxnPjwvZz4KPC9zdmc+"  data-original="https://s2.loli.net/2023/02/16/6yZpdQtXg7IhUPn.png" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAANSURBVBhXYzh8+PB/AAffA0nNPuCLAAAAAElFTkSuQmCC" alt="iscsi-win.png"></p>

</li>
<li><p>MS-SMB<br><img class="lazyload lazyload-style-1" src="data:image/svg+xml;base64,PCEtLUFyZ29uTG9hZGluZy0tPgo8c3ZnIHdpZHRoPSIxIiBoZWlnaHQ9IjEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgc3Ryb2tlPSIjZmZmZmZmMDAiPjxnPjwvZz4KPC9zdmc+"  data-original="https://s2.loli.net/2023/02/16/vSm7T3QYq4KIdtc.png" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAANSURBVBhXYzh8+PB/AAffA0nNPuCLAAAAAElFTkSuQmCC" alt="smb.png"></p>

</li>
</ul>
</br>
</br>


<h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p>设置：</p>
<ul>
<li>分了12个CPU 40G内存</li>
<li>NixOS,Linux 5.15</li>
<li>MTU 9000</li>
<li>NFS Flags:  rw,relatime,vers=4.2,rsize=131072,wsize=131072,namlen=255,hard,async,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.10.10.4,local_lock=none,addr=10.10.10.11</li>
</ul>
<p>有空再想想怎么写这个，测的话如果走内存，又没啥好看的，然后还有meta dev的测试好像就是905p的iops自己搜一下就行了，当然我这个cpu带不动的。机械硬盘池的话因为已经用了50%多了，好像还是没啥好看的，有空琢磨一下怎么写吧。</p>
<h3 id="iperf3-1"><a href="#iperf3-1" class="headerlink" title="iperf3"></a>iperf3</h3><pre><code class="bash">[ ID] Interval           Transfer     Bitrate
[  5]   0.00-5.00   sec   958 MBytes  1.61 Gbits/sec                  receiver
[  8]   0.00-5.00   sec   975 MBytes  1.64 Gbits/sec                  receiver
[ 10]   0.00-5.00   sec   969 MBytes  1.63 Gbits/sec                  receiver
[ 12]   0.00-5.00   sec   980 MBytes  1.64 Gbits/sec                  receiver
[ 14]   0.00-5.00   sec   975 MBytes  1.63 Gbits/sec                  receiver
[ 16]   0.00-5.00   sec   980 MBytes  1.64 Gbits/sec                  receiver
[ 18]   0.00-5.00   sec   993 MBytes  1.67 Gbits/sec                  receiver
[ 20]   0.00-5.00   sec   998 MBytes  1.67 Gbits/sec                  receiver
[ 22]   0.00-5.00   sec  1008 MBytes  1.69 Gbits/sec                  receiver
[ 24]   0.00-5.00   sec   972 MBytes  1.63 Gbits/sec                  receiver
[ 26]   0.00-5.00   sec   993 MBytes  1.67 Gbits/sec                  receiver
[ 28]   0.00-5.00   sec   988 MBytes  1.66 Gbits/sec                  receiver
[ 30]   0.00-5.00   sec   988 MBytes  1.66 Gbits/sec                  receiver
[ 32]   0.00-5.00   sec   966 MBytes  1.62 Gbits/sec                  receiver
[ 34]   0.00-5.00   sec   984 MBytes  1.65 Gbits/sec                  receiver
[ 36]   0.00-5.00   sec  1007 MBytes  1.69 Gbits/sec                  receiver
[ 38]   0.00-5.00   sec   980 MBytes  1.64 Gbits/sec                  receiver
[ 40]   0.00-5.00   sec   983 MBytes  1.65 Gbits/sec                  receiver
[ 42]   0.00-5.00   sec   982 MBytes  1.65 Gbits/sec                  receiver
[ 44]   0.00-5.00   sec   976 MBytes  1.64 Gbits/sec                  receiver
[ 46]   0.00-5.00   sec  2.88 GBytes  4.95 Gbits/sec                  receiver
[ 48]   0.00-5.00   sec   984 MBytes  1.65 Gbits/sec                  receiver
[ 50]   0.00-5.00   sec   994 MBytes  1.67 Gbits/sec                  receiver
[ 52]   0.00-5.00   sec  1.11 GBytes  1.91 Gbits/sec                  receiver
[SUM]   0.00-5.00   sec  25.1 GBytes  43.2 Gbits/sec                  receiver</code></pre>
<h3 id="FIO"><a href="#FIO" class="headerlink" title="FIO"></a>FIO</h3><h4 id="写入相关"><a href="#写入相关" class="headerlink" title="写入相关"></a>写入相关</h4><ul>
<li>4k随机写</li>
</ul>
<pre><code class="bash">fio -filename=test-rand-write -ioengine=libaio -bs=4k -size=10G -numjobs=24 -iodepth=32 -runtime=60 -thread -rw=randwrite -group_reporting -name=&quot;randwrite&quot;</code></pre>
<pre><code class="bash">randwrite: (groupid=0, jobs=24): err= 0: pid=2251134: Thu Feb 16 16:32:01 2023
  write: IOPS=49.4k, BW=193MiB/s (202MB/s)(12.6GiB/66882msec); 0 zone resets
    slat (usec): min=2, max=15423k, avg=482.15, stdev=58552.02
    clat (usec): min=3, max=15484k, avg=14999.99, stdev=360480.85
     lat (usec): min=142, max=15484k, avg=15482.14, stdev=366436.81
    clat percentiles (usec):
     |  1.00th=[     157],  5.00th=[     251], 10.00th=[     330],
     | 20.00th=[     437], 30.00th=[     537], 40.00th=[     627],
     | 50.00th=[     717], 60.00th=[     791], 70.00th=[     865],
     | 80.00th=[    1631], 90.00th=[    5800], 95.00th=[   10028],
     | 99.00th=[   19530], 99.50th=[   28967], 99.90th=[ 7549748],
     | 99.95th=[ 9059697], 99.99th=[15502148]
   bw (  KiB/s): min=  280, max=1929744, per=100.00%, avg=814115.55, stdev=27422.74, samples=780
   iops        : min=   70, max=482436, avg=203528.73, stdev=6855.69, samples=780
  lat (usec)   : 4=0.01%, 10=0.01%, 20=0.01%, 250=5.00%, 500=21.57%
  lat (usec)   : 750=27.79%, 1000=24.14%
  lat (msec)   : 2=1.82%, 4=3.04%, 10=11.67%, 20=4.04%, 50=0.53%
  lat (msec)   : 100=0.06%, 250=0.14%, 500=0.05%, 750=0.01%, 1000=0.01%
  lat (msec)   : 2000=0.01%, &gt;=2000=0.14%
  cpu          : usr=0.53%, sys=3.79%, ctx=496046, majf=0, minf=24
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, &gt;=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, &gt;=64=0.0%
     issued rwts: total=0,3303411,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32
Run status group 0 (all jobs):
  WRITE: bw=193MiB/s (202MB/s), 193MiB/s-193MiB/s (202MB/s-202MB/s), io=12.6GiB (13.5GB), run=66882-66882msec</code></pre>
</br>
</br>

<ul>
<li>1M顺序写</li>
</ul>
<pre><code class="bash">fio -filename=test-write -ioengine=libaio -bs=1M -size=10G -numjobs=24 -iodepth=32 -runtime=60 -thread -rw=write -group_reporting -name=&quot;write&quot;</code></pre>
<pre><code class="bash">write: (groupid=0, jobs=24): err= 0: pid=2258302: Thu Feb 16 16:44:20 2023
  write: IOPS=2833, BW=2834MiB/s (2971MB/s)(168GiB/60747msec); 0 zone resets
    slat (usec): min=182, max=7100.7k, avg=8453.00, stdev=94600.26
    clat (usec): min=5, max=7500.7k, avg=260924.86, stdev=552308.55
     lat (msec): min=11, max=7512, avg=269.38, stdev=561.22
    clat percentiles (msec):
     |  1.00th=[  113],  5.00th=[  136], 10.00th=[  146], 20.00th=[  159],
     | 30.00th=[  167], 40.00th=[  176], 50.00th=[  184], 60.00th=[  192],
     | 70.00th=[  201], 80.00th=[  211], 90.00th=[  230], 95.00th=[  259],
     | 99.00th=[ 2123], 99.50th=[ 3306], 99.90th=[ 7416], 99.95th=[ 7416],
     | 99.99th=[ 7483]
   bw (  MiB/s): min=  103, max= 5308, per=100.00%, avg=3626.54, stdev=48.04, samples=2268
   iops        : min=   97, max= 5306, avg=3625.18, stdev=48.09, samples=2268
  lat (usec)   : 10=0.01%, 50=0.01%
  lat (msec)   : 20=0.01%, 50=0.03%, 100=0.32%, 250=93.96%, 500=2.00%
  lat (msec)   : 750=0.30%, 1000=0.38%, 2000=1.66%, &gt;=2000=1.33%
  cpu          : usr=0.44%, sys=23.26%, ctx=76380, majf=0, minf=25
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.2%, 32=99.6%, &gt;=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, &gt;=64=0.0%
     issued rwts: total=0,172146,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32
Run status group 0 (all jobs):
  WRITE: bw=2834MiB/s (2971MB/s), 2834MiB/s-2834MiB/s (2971MB/s-2971MB/s), io=168GiB (181GB), run=60747-60747msec</code></pre>
<h4 id="读取相关"><a href="#读取相关" class="headerlink" title="读取相关"></a>读取相关</h4><p>读取测试其实还是要看实际场景软件的，下面的测试太理想化了，加<code>-direct=1</code>测好像又没意义，不加又有命中率的事情，随便看看图个乐吧。</p>
<ul>
<li>4k随机读取</li>
</ul>
<pre><code class="bash"> fio -filename=test-rand-read -ioengine=libaio -bs=4k -size=10G -numjobs=24 -iodepth=32 -runtime=60 -thread -rw=randread -group_reporting -name=&quot;randread&quot;</code></pre>
<pre><code class="bash">randread: (groupid=0, jobs=24): err= 0: pid=2260684: Thu Feb 16 16:48:58 2023
  read: IOPS=50.0k, BW=195MiB/s (205MB/s)(11.4GiB/60003msec)
    slat (nsec): min=1932, max=149087k, avg=476537.26, stdev=855570.75
    clat (usec): min=3, max=166765, avg=14874.41, stdev=6683.97
     lat (usec): min=7, max=167317, avg=15350.95, stdev=6844.11
    clat percentiles (msec):
     |  1.00th=[    6],  5.00th=[    7], 10.00th=[    9], 20.00th=[   10],
     | 30.00th=[   12], 40.00th=[   13], 50.00th=[   14], 60.00th=[   16],
     | 70.00th=[   18], 80.00th=[   20], 90.00th=[   23], 95.00th=[   24],
     | 99.00th=[   40], 99.50th=[   45], 99.90th=[   56], 99.95th=[   63],
     | 99.99th=[  163]
   bw (  KiB/s): min=118708, max=359568, per=99.41%, avg=198860.20, stdev=2670.29, samples=2856
   iops        : min=29675, max=89892, avg=49715.03, stdev=667.57, samples=2856
  lat (usec)   : 4=0.01%, 10=0.01%, 20=0.01%, 50=0.01%, 500=0.01%
  lat (usec)   : 750=0.01%, 1000=0.01%
  lat (msec)   : 2=0.01%, 4=0.27%, 10=22.40%, 20=58.79%, 50=18.32%
  lat (msec)   : 100=0.18%, 250=0.02%
  cpu          : usr=0.87%, sys=2.23%, ctx=1820208, majf=0, minf=792
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=100.0%, &gt;=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, &gt;=64=0.0%
     issued rwts: total=3000750,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32
Run status group 0 (all jobs):
   READ: bw=195MiB/s (205MB/s), 195MiB/s-195MiB/s (205MB/s-205MB/s), io=11.4GiB (12.3GB), run=60003-60003msec</code></pre>
</br>
</br>

<ul>
<li>1M顺序读取</li>
</ul>
<pre><code class="bash">fio -filename=test-read -ioengine=libaio -bs=1M -size=10G -numjobs=24 -iodepth=32 -runtime=60 -thread -rw=read -group_reporting -name=&quot;read&quot;</code></pre>
<pre><code class="bash">read: (groupid=0, jobs=24): err= 0: pid=2262359: Thu Feb 16 16:51:39 2023
  read: IOPS=8368, BW=8369MiB/s (8775MB/s)(240GiB/29367msec)
    slat (usec): min=85, max=74615, avg=2855.92, stdev=2478.60
    clat (usec): min=4, max=217900, avg=88764.77, stdev=22209.24
     lat (usec): min=1824, max=219305, avg=91620.69, stdev=22776.37
    clat percentiles (msec):
     |  1.00th=[   35],  5.00th=[   60], 10.00th=[   66], 20.00th=[   72],
     | 30.00th=[   77], 40.00th=[   81], 50.00th=[   86], 60.00th=[   92],
     | 70.00th=[  100], 80.00th=[  107], 90.00th=[  118], 95.00th=[  128],
     | 99.00th=[  150], 99.50th=[  163], 99.90th=[  180], 99.95th=[  184],
     | 99.99th=[  201]
   bw (  MiB/s): min= 5642, max=11347, per=99.86%, avg=8357.27, stdev=62.64, samples=1392
   iops        : min= 5642, max=11346, avg=8356.07, stdev=62.61, samples=1392
  lat (usec)   : 10=0.01%, 20=0.01%
  lat (msec)   : 2=0.01%, 4=0.01%, 10=0.02%, 20=0.07%, 50=2.47%
  lat (msec)   : 100=68.50%, 250=28.92%
  cpu          : usr=0.31%, sys=19.00%, ctx=6755544, majf=0, minf=196632
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.2%, 32=99.7%, &gt;=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.1%, 64=0.0%, &gt;=64=0.0%
     issued rwts: total=245760,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=32
Run status group 0 (all jobs):
   READ: bw=8369MiB/s (8775MB/s), 8369MiB/s-8369MiB/s (8775MB/s-8775MB/s), io=240GiB (258GB), run=29367-29367msec</code></pre>
</br>
</br>


<h1 id="10-一些题外话"><a href="#10-一些题外话" class="headerlink" title="10 一些题外话"></a>10 一些题外话</h1><ul>
<li><p>非常喜欢用网卡ipxe+Ventoy这套东西跑系统，最近发现Mikrotik ROS系统在DHCP Server选项中增加了一个<code>Option Matcher</code>的功能。配合Option 93可以根据主板的架构分配不同的引导文件e.g.ArmUEFI,LegacyBIOS,x86UEFI.</p>
</li>
<li><p>MTU 9000, AKA <code>Jumbo Frames</code>, 你需要慎重去考虑你整个网络内的所有设备通信，这个东西带来的收益其实远比它带来的问题多，如果你家里有很多无线智能设备的话，考虑尽可能用vlan去划分。网络inbound的话，需要修正mss，Mikrotik ROS则加一条mangle：</p>
<pre><code class="bash">/ip firewall mangle add action=change-mss chain=forward new-mss=clamp-to-pmtu passthrough=yes protocol=tcp tcp-flags=syn</code></pre>
</li>
</ul>

	</div>

	

	

	
		<div class="post-tags">
			<i class="fa fa-tags" aria-hidden="true"></i>
			<a class="tag badge badge-secondary post-meta-detail-tag -none-link" href="/tags/Hardware/" rel="tag">Hardware</a><a class="tag badge badge-secondary post-meta-detail-tag -none-link" href="/tags/NAS/" rel="tag">NAS</a>
		</div>
	
</article>

	<div id="share_container">
	<div id="share" data-initialized="true">
		<a class="no-pjax icon-wechat" tooltip="分享到微信">
			<button class="btn btn-icon btn-success">
				<span class="btn-inner--icon"><i class="fa fa-weixin"></i></span>
			</button>
		</a>
		<a target="_blank" class="no-pjax icon-douban" tooltip="分享到豆瓣">
			<button class="btn btn-icon btn-primary" style="background: #209261;border: none;">
				豆
			</button>
		</a>
		<a target="_blank" class="no-pjax icon-qq" tooltip="分享到 QQ">
			<button class="btn btn-icon btn-primary" style="background: #2196f3;border: none;">
				<span class="btn-inner--icon"><i class="fa fa-qq"></i></span>
			</button>
		</a>
		<a target="_blank" class="no-pjax icon-qzone" tooltip="分享到 QQ 空间">
			<button class="btn btn-icon btn-primary" style="background: #ffc107;border: none;">
				<span class="btn-inner--icon"><i class="fa fa-star"></i></span>
			</button>
		</a>
		<a target="_blank" class="no-pjax icon-weibo" tooltip="分享到微博">
			<button class="btn btn-icon btn-warning">
				<span class="btn-inner--icon"><i class="fa fa-weibo"></i></span>
			</button>
		</a>
		<a target="_blank" class="no-pjax icon-facebook" tooltip="分享到 Facebook">
			<button class="btn btn-icon btn-primary" style="background: #283593;border: none;">
				<span class="btn-inner--icon"><i class="fa fa-facebook"></i></span>
			</button>
		</a>
		<a target="_blank" class="no-pjax icon-twitter" tooltip="分享到 Twitter">
			<button class="btn btn-icon btn-primary" style="background: #03a9f4;border: none;">
				<span class="btn-inner--icon"><i class="fa fa-twitter"></i></span>
			</button>
		</a>
		<a target="_blank" class="no-pjax icon-telegram" href="https://telegram.me/share/url?url=https://blog.xjn819.com/post/Upgrade-from-10Gbps-to-40Gbps-network.html&text=ZFS:从10Gbps升级到40Gbps网络" tooltip="分享到 Telegram">
			<button class="btn btn-icon btn-primary" style="background: #42a5f5;border: none;">
				<span class="btn-inner--icon"><i class="fa fa-telegram"></i></span>
			</button>
		</a>
		<a target="_blank" class="no-pjax icon-copy-link" id="share_copy_link" tooltip="复制链接">
			<button class="btn btn-icon btn-default">
				<span class="btn-inner--icon"><i class="fa fa-link"></i></span>
			</button>
		</a>
	</div>
	<button id="share_show" class="btn btn-icon btn-primary" tooltip="分享">
		<span class="btn-inner--icon"><i class="fa fa-share"></i></span>
	</button>
</div>
<script type="text/javascript">
	socialShare("#share", {
	    title : 'ZFS:从10Gbps升级到40Gbps网络',
	    description : '0 介绍自TrueNAS Core更新至FreeBSD 13，它的两大免费产品Scale和Core都...',
	    wechatQrcodeTitle : "分享到微信",
	    wechatQrcodeHelper : '微信扫描二维码',
	    source : 'https://blog.xjn819.com/post/Upgrade-from-10Gbps-to-40Gbps-network.html'
	});
	$("#share_show")[0].onclick = function(){
		$("#share_container").addClass("opened");
	};
	$("#share_copy_link")[0].onclick = function(){
		let input = document.createElement('input');
		document.body.appendChild(input);
		input.setAttribute("value", window.location.href);
		input.setAttribute("readonly", "readonly");
		input.setAttribute("style", "opacity: 0;mouse-events:none;");
		input.select();
		if (document.execCommand('copy')){
			iziToast.show({
				title: '链接已复制',
				message: "链接已复制到剪贴板",
				class: 'shadow',
				position: 'topRight',
				backgroundColor: '#2dce89',
				titleColor: '#ffffff',
				messageColor: '#ffffff',
				iconColor: '#ffffff',
				progressBarColor: '#ffffff',
				icon: 'fa fa-check',
				timeout: 5000
			});
		}else{
			iziToast.show({
				title: '复制失败',
				message: "请手动复制链接",
				class: 'shadow',
				position: 'topRight',
				backgroundColor: '#f5365c',
				titleColor: '#ffffff',
				messageColor: '#ffffff',
				iconColor: '#ffffff',
				progressBarColor: '#ffffff',
				icon: 'fa fa-close',
				timeout: 5000
			});
		}
		document.body.removeChild(input);
	};
</script>


<div id="post_comment" class="card shadow-sm">
	<div id="gitalk-container"></div>
<script type="text/javascript">
	var gitalk = new Gitalk({
		clientID: '86a6322e810d06834891',
		clientSecret: 'eaf77d01ffaddf2f06a2a4bbac944d8cca3d0c91',
		repo: 'OCNHTeam.github.io',
		owner: 'OCNHTeam',
		admin: ['SeonMe'],
		id: location.pathname,
		distractionFreeMode: false
	})
	gitalk.render('gitalk-container');
</script>

</div>


<div class="post-navigation card shadow-sm"><div class="post-navigation-item post-navigation-pre"></div><div class="post-navigation-item post-navigation-next"><span class="page-navigation-extra-text">下一篇 <i class="fa fa-arrow-circle-o-right" aria-hidden="true"></i></span><a href="/post/apple-tv-wee-guide.html" rel="next"> Apple TV小指南</a></div></div>



		
		
		
		

					<footer id="footer" class="site-footer card shadow-sm border-0">
						
						<div>Theme <a target="_blank" rel="noopener" href="https://github.com/solstice23/hexo-theme-argon"><strong>Argon</strong></a> | Powered by Hexo</div>
						<span id="busuanzi_container_site_uv">
							本站访客数 <span id="busuanzi_value_site_uv"></span> 人次
						</span>
					</footer>
				</main>
			</div>
		</div>
		
<script src="/argontheme.js"></script>

		
		
		

		
			<script>
				var argonEnableCodeHighlight = true;
			</script>
			
<link rel="stylesheet" href="/assets/vendor/highlight/styles/vs2015.css">

		

	</div>
</div>
<noscript>
	<style>
		article img.lazyload[src^="data:image/svg+xml;base64,PCEtLUFyZ29uTG9hZGluZy0tPg"]{display: none;}
		.comment-item-text .comment-sticker.lazyload{display: none;}
	</style>
</noscript>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0SS4LFYBFR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0SS4LFYBFR');
</script>
</body>



</html>

